{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1463f153-71d2-480c-8565-a0adcdf2b21f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Korean LLM (Large Language Model) Serving on SageMaker with Hugging Face TGI (Text Generation Inference)\n",
    "---\n",
    "\n",
    "한국어 LLM 모델 SageMaker 서빙 핸즈온 (허깅페이스 허브에서 모델을 그대로 배포). TGI (Text Generation Inference) 라이브러리 사용\n",
    "\n",
    "- [Hugging Face TGI Repository](https://github.com/huggingface/text-generation-inference)\n",
    "- [Hugging Face Blog: Introducing the Hugging Face LLM Inference Container for Amazon SageMaker](https://huggingface.co/blog/sagemaker-huggingface-llm)\n",
    "- [AWS Blog: Announcing the launch of new Hugging Face LLM Inference containers on Amazon SageMaker](https://aws.amazon.com/ko/blogs/machine-learning/announcing-the-launch-of-new-hugging-face-llm-inference-containers-on-amazon-sagemaker/)\n",
    "\n",
    "\n",
    "---\n",
    "출처: [AWS AIML GenAI workshop for Korean language](https://github.com/aws-samples/aws-ai-ml-workshop-kr/blob/master/genai/jumpstart/text_to_text/%5Bmodel_consumer%5Dkullm_polyglot_12_8b_in_context_learning_ml_g5_12xl.ipynb)\n",
    "\n",
    "이 모델은 SageMaker Deployment에서 [text-generation-inference](https://github.com/huggingface/text-generation-inference/tree/main)를 활용하여 Endpoint를 생성합니다. text-generation-inference 는 텍스트 생성 추론을 위한 Rust, Python 및 gRPC 서버이며, HuggingFace의 production에서 LLM의 API 추론 위젯을 구동하는 데 사용됩니다.\n",
    "\n",
    "[주요 특성]\n",
    "- 간단한 launcher로 가장 인기 있는 대규모 언어 모델 제공\n",
    "- 여러 GPU에서 더 빠른 추론을 위한 텐서 병렬 처리\n",
    "- 서버 전송 이벤트(SSE, Server-Sent Events)를 사용한 토큰 스트리밍\n",
    "- 총 처리량 증가를 위한 수신 요청의 지속적인 batching 처리\n",
    "- 가장 많이 사용되는 아키텍처에 flash-attention을 사용하여 추론하도록 최적화된 transformers 코드\n",
    "- bitsandbytes을 이용한 Quantization\n",
    "- Safetensors 가중치 로딩\n",
    "- 대규모 언어 모델용 워터마크를 사용한 워터마킹\n",
    "- Logits 와퍼(temperature 스케일링, top-p, top-k, repetition penalty, 자세한 내용은 transformers.LogitsProcessor 참조)\n",
    "- 시퀀스 중지\n",
    "- 로그 확률\n",
    "- 프로덕션 준비 완료(Open Telemetry, Prometheus metrics를 사용한 분산 추적)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c65dd9a-252a-42cf-a69a-2db7ac0d7b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "sys.path.append('../templates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f65ddc-6261-4280-8203-eee331632062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -qU boto3 huggingface_hub sagemaker langchain deepspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0333c-9e5f-43d9-b062-66519d9eb4f3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Serve LLM Model on SageMaker\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690bda67-b335-4fe3-a72a-e360249dfc28",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f26242-65fd-471a-b1c8-a64bc686e32e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.model import Model\n",
    "from sagemaker import script_uris, image_uris, model_uris, get_execution_role\n",
    "from sagemaker.utils import name_from_base\n",
    "import logging\n",
    "import boto3\n",
    "import time\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c06035-ec39-4ebd-830f-49d4c164e600",
   "metadata": {},
   "source": [
    "### Setup essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbe1bbc7-303f-495c-95a1-a1ae1ea39464",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sagemaker==2.173.0\n",
      "Using boto3==1.28.15\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "logger.info(f'Using sagemaker=={sagemaker.__version__}')\n",
    "logger.info(f'Using boto3=={boto3.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb8dc308-3283-4dc1-b75e-9c4bb0309a89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Role => arn:aws:iam::143656149352:role/service-role/AmazonSageMaker-ExecutionRole-20220317T150353\n"
     ]
    }
   ],
   "source": [
    "# MODEL_ID = 'kullm-polyglot-5-8b-v2'  # the error is that \"Expected (head_size % 8 == 0) && (head_size <= 128) to be true, but got false. \"\n",
    "MODEL_ID = \"nlpai-lab/kullm-polyglot-12.8b-v2\"\n",
    "MODEL_PREFIX = MODEL_ID.split('/')[-1].replace('.', '-')\n",
    "\n",
    "MODEL_VERSION = '*'\n",
    "INSTANCE_TYPE = 'ml.g5.24xlarge'\n",
    "INSTANCE_COUNT = 1\n",
    "IMAGE_SCOPE = 'inference'\n",
    "MODEL_DATA_DOWNLOAD_TIMEOUT = 3600  # in seconds\n",
    "CONTAINER_STARTUP_HEALTH_CHECK_TIMEOUT = 360\n",
    "EBS_VOLUME_SIZE = 256  # in GB\n",
    "CONTENT_TYPE = 'application/json'\n",
    "\n",
    "# set up roles and clients \n",
    "client = boto3.client('sagemaker-runtime')\n",
    "ROLE = get_execution_role()\n",
    "logger.info(f'Role => {ROLE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd4f20-e455-4b9b-a1ca-2b6e3481d5ca",
   "metadata": {},
   "source": [
    "### Retrieve Hugging Face LLM DLC for TGI\n",
    "\n",
    "- https://github.com/aws/deep-learning-containers/blob/master/available_images.md#huggingface-text-generation-inference-containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37de4c14-a8d0-4b8a-bd8c-f580f3ecf5e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to only available Python version: py39\n",
      "Defaulting to only supported image scope: gpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.0-tgi0.8.2-gpu-py39-cu118-ubuntu20.04'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "deploy_image_uri = get_huggingface_llm_image_uri(\n",
    "  backend=\"huggingface\", # or lmi\n",
    "  region=region\n",
    ")\n",
    "deploy_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5341f604-a2bf-4748-b8d5-8343df5322f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = {\n",
    "    'HF_TASK': 'text-generation',\n",
    "    'HF_MODEL_ID': MODEL_ID,\n",
    "    'SAGEMAKER_MODEL_SERVER_TIMEOUT': str(3600),\n",
    "    'SM_NUM_GPUS': '4',  ## ml.g5.12xlarge 기준\n",
    "    'HF_MODEL_QUANTIZE': 'bitsandbytes',  ##[possible values: bitsandbytes, gptq]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33fce053-033f-4fb6-af2f-bdc92aaaa64a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Endpoint name: kullm-polyglot-12-8b-v2-tgi-2023-07-23-14-05-06-080\n"
     ]
    }
   ],
   "source": [
    "endpoint_name =  name_from_base(f\"{MODEL_PREFIX}-tgi\")\n",
    "logger.info(f'Endpoint name: {endpoint_name}')\n",
    "\n",
    "model = HuggingFaceModel(\n",
    "    image_uri=deploy_image_uri,\n",
    "    env=env,\n",
    "    role=ROLE,\n",
    "    name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb8824e-1b00-4c3d-87f5-3555108585d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deploy model to SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df2669fe-c5b3-4978-8eb4-61825f5e8276",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating model with name: kullm-polyglot-12-8b-v2-tgi-2023-07-23-14-05-06-080\n",
      "CreateModel request: {\n",
      "    \"ModelName\": \"kullm-polyglot-12-8b-v2-tgi-2023-07-23-14-05-06-080\",\n",
      "    \"ExecutionRoleArn\": \"arn:aws:iam::143656149352:role/service-role/AmazonSageMaker-ExecutionRole-20220317T150353\",\n",
      "    \"PrimaryContainer\": {\n",
      "        \"Image\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.0-tgi0.8.2-gpu-py39-cu118-ubuntu20.04\",\n",
      "        \"Environment\": {\n",
      "            \"HF_TASK\": \"text-generation\",\n",
      "            \"HF_MODEL_ID\": \"nlpai-lab/kullm-polyglot-12.8b-v2\",\n",
      "            \"SAGEMAKER_MODEL_SERVER_TIMEOUT\": \"3600\",\n",
      "            \"SM_NUM_GPUS\": \"4\",\n",
      "            \"HF_MODEL_QUANTIZE\": \"bitsandbytes\",\n",
      "            \"SAGEMAKER_PROGRAM\": \"\",\n",
      "            \"SAGEMAKER_SUBMIT_DIRECTORY\": \"\",\n",
      "            \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\n",
      "            \"SAGEMAKER_REGION\": \"us-east-1\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Creating endpoint-config with name kullm-polyglot-12-8b-v2-tgi-2023-07-23-14-05-06-080\n",
      "Creating endpoint with name kullm-polyglot-12-8b-v2-tgi-2023-07-23-14-05-06-080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 69.6 ms, sys: 6.08 ms, total: 75.6 ms\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=INSTANCE_COUNT, \n",
    "    instance_type=INSTANCE_TYPE, \n",
    "    endpoint_name=endpoint_name, \n",
    "    # volume_size=EBS_VOLUME_SIZE, # If using an instance with local SSD storage, volume_size must be None, e.g. p4 but not p3    \n",
    "    model_data_download_timeout=MODEL_DATA_DOWNLOAD_TIMEOUT, \n",
    "    container_startup_health_check_timeout=CONTAINER_STARTUP_HEALTH_CHECK_TIMEOUT, \n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37b4ac7f-b89a-45bf-9be2-ec6090b29ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b> [SageMaker LLM Serving] <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/endpoints/kullm-polyglot-12-8b-v2-tgi-2023-07-23-14-05-06-080\">Check Endpoint Status</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "def make_console_link(region, endpoint_name, task='[SageMaker LLM Serving]'):\n",
    "    endpoint_link = f'<b> {task} <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={region}#/endpoints/{endpoint_name}\">Check Endpoint Status</a></b>'   \n",
    "    return endpoint_link\n",
    "\n",
    "endpoint_link = make_console_link(region, endpoint_name)\n",
    "display(HTML(endpoint_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "258d5dca-d5bc-43f1-bac9-fda0a20d07b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint is  InService\n",
      "CPU times: user 22.5 ms, sys: 0 ns, total: 22.5 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from inference_lib import describe_endpoint, Prompter\n",
    "describe_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7870b3ee-17fe-4f6b-85c6-2a05b290daa2",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Inference\n",
    "---\n",
    "\n",
    "엔드포인트를 호출할 때 이 텍스트를 JSON 페이로드 내에 제공해야 합니다. 이 JSON 페이로드에는 length, sampling strategy, output token sequence restrictions을 제어하는 데 도움이 되는 원하는 추론 매개변수가 포함될 수 있습니다. 허깅페이스 트랜스포머 transformers 라이브러리에는 [사용 가능한 페이로드 매개변수](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig)의 전체 목록이 정의되어 있지만, 중요한 페이로드 매개변수는 다음과 같이 정의되어 있습니다:\n",
    "\n",
    "* **do_sample (`bool`)** – logits sampling 활성화\n",
    "* **max_new_tokens (`int`)** – 생성된 토큰의 최대 수\n",
    "* **best_of (`int`)** – best_of 개의 시퀀스를 생성하고 가장 높은 토큰 로그 확률이 있는 경우 반환\n",
    "* **repetition_penalty (`float`)** – 반복 패널티에 대한 파라미터, 1.0은 패널티가 없음을 의미하여 Greedy 서치와 동일, 커질수록 다양한 결과를 얻을 수 있으며, 자세한 사항은 [this paper](https://arxiv.org/pdf/1909.05858.pdf)을 참고\n",
    "* **return_full_text (`bool`)** – 생성된 텍스트에 프롬프트를 추가할지 여부\n",
    "* **seed (`int`)** – Random sampling seed\n",
    "* **stop_sequences (`List[str]`)** – `stop_sequences` 가 생성되면 토큰 생성을 중지\n",
    "* **temperature (`float`)** – logits 분포 모듈화에 사용되는 값\n",
    "* **top_k (`int`)** – 상위 K개 만큼 가장 높은 확률 어휘 토큰의 수\n",
    "* **top_p (`float`)** – 1 보다 작게 설정하게 되며, 상위부터 정렬했을 때 가능한 토큰들의 확률을 합산하여 `top_p` 이상의 가장 작은 집합을 유지\n",
    "* **truncate (`int`)** – 입력 토큰을 지정된 크기로 잘라냄\n",
    "* **typical_p (`float`)** – typical Decoding 양으로, 자세한 사항은 [Typical Decoding for Natural Language Generation](https://arxiv.org/abs/2202.00666)을 참고\n",
    "* **watermark (`bool`)** –  [A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226)가 Watermarking\n",
    "* **decoder_input_details (`bool`)** – decoder input token logprobs와 ids를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "591828a0-294d-4a52-9ef0-d1edfa1d4f24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"do_sample\": False,\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.9,\n",
    "    \"return_full_text\": True,\n",
    "    \"repetition_penalty\": 1.3,\n",
    "    \"presence_penalty\": None,\n",
    "    \"eos_token_id\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70c3a605-572c-49bd-8ffa-8851d86e255e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "고객님: 안녕하세요, iPhone에 문제가 있습니다.\n",
    "상담원: 안녕하세요! 무슨 문제인가요?\n",
    "고객님: 휴대폰이 제대로 충전되지 않고 배터리가 매우 빨리 소모되는 것 같습니다. 다른 충전 케이블과 전원 어댑터를 사용해 보았지만 문제가 지속됩니다.\n",
    "상담원: 흠, 그렇군요. 몇 가지 문제 해결 단계를 시도해 보겠습니다. 설정, 배터리로 이동하여 배터리 수명을 많이 소모하는 앱이 있는지 확인해 주시겠어요?\n",
    "고객님: 예, 배터리를 많이 소모하는 앱이 몇 개 있습니다.\n",
    "상담원: 좋아요, 화면 하단에서 위로 스와이프하여 해당 앱을 강제 종료한 다음 앱을 위로 스와이프하여 닫아 보세요.\n",
    "고객: 그렇게 했는데도 문제가 여전히 남아 있습니다.\n",
    "상담원: 네, iPhone의 설정을 기본값으로 재설정해 보겠습니다. 이렇게 해도 데이터가 삭제되지는 않습니다. 설정, 일반, 재설정으로 이동한 다음 모든 설정 재설정을 선택하세요.\n",
    "고객님: 그렇게 했습니다. 다음은 어떻게 해야 하나요?\n",
    "상담원: 이제 iPhone을 재시동해 보겠습니다. \"밀어서 전원 끄기\" 옵션이 표시될 때까지 전원 버튼을 길게 누릅니다. 밀어 전원을 끄고 몇 초간 기다린 다음 iPhone을 다시 켜세요.\n",
    "고객님: 다시 시작했지만 여전히 제대로 충전되지 않습니다.\n",
    "상담원: 그렇군요. iPhone에서 진단 테스트를 실행해야 할 것 같습니다. 가까운 Apple Store 또는 공인 서비스 제공업체를 방문하여 iPhone을 점검받으시기 바랍니다.\n",
    "고객: 예약을 해야 하나요?\n",
    "상담원: 예. 줄을 서서 기다리지 않으려면 항상 미리 예약하는 것이 가장 좋습니다. 온라인으로 예약하거나 Apple Store 또는 공인 서비스 제공업체에 전화하여 예약할 수 있습니다.\n",
    "고객님: 수리 비용은 제가 지불해야 하나요?\n",
    "상담원: iPhone에 보증이 적용되는지 여부에 따라 다릅니다. 보증이 적용되는 경우에는 비용을 지불할 필요가 없습니다. 그러나 보증이 적용되지 않는 경우에는 수리 비용을 지불하셔야 합니다.\n",
    "고객님: iPhone을 돌려받는 데 얼마나 걸리나요?\n",
    "상담원: 문제의 심각도에 따라 다르지만 일반적으로 영업일 기준 1~2일이 소요됩니다.\n",
    "고객: 온라인으로 수리 상태를 추적할 수 있나요?\n",
    "상담원: 온라인 또는 Apple Store 또는 공인 서비스 제공업체에 전화하여 수리 상태를 추적할 수 있습니다.\n",
    "고객: 알겠습니다. 도와주셔서 감사합니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db9f3e-1b84-483e-bb36-6b205ad4a51a",
   "metadata": {},
   "source": [
    "Generation configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a676c28a-205c-410e-8dbe-c35ccf64829d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from inference_lib import KoLLMSageMakerEndpoint\n",
    "\n",
    "ep = KoLLMSageMakerEndpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a896590-26f1-4a75-bb6a-7636b409c5b7",
   "metadata": {},
   "source": [
    "### A. Text Summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a51823a0-61a4-4954-92d9-0337b34a8da3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 134 µs, sys: 18 µs, total: 152 µs\n",
      "Wall time: 136 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "instruction = \"다음 대화를 요약해 주세요\"\n",
    "payload = ep.get_payload(instruction, input_text, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ec37335-5c0d-47ba-a8ad-cf1a03d5bcfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Response: 1) 고객이 아이폰에 대한 문의 사항이나 문제 발생 시 상담사와 연결 가능한지 묻는다.\\n2'\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generated_text = ep.infer(payload, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f297221e-f7fa-4b4e-9e93-634ba647dbce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### B. Abstractive Question Answering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af902e9c-7ba3-4d0e-890f-3235000208cc",
   "metadata": {},
   "source": [
    "##### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49d6c8fa-5b07-4b21-999d-9f8947d85253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = 'iPhone 충전 문제를 해결하기 위해 고객에게 어떤 문제 해결 단계를 제안했나요?'\n",
    "payload = ep.get_payload(instruction, input_text, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "605ebcdb-c52a-4d75-9792-250de934061f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Response: A/S 센터 직원으로서 저자는 iPhone 충전 문제를 해결하고 원활한 작동 환경을 조성하고자 하므로 이 과제를 '\n",
      " '수행함으로써 잠재적인 해결책을 찾으려고 노력 중임을 나타냅니다. 첫 번째 조치로서 사용자에게 iOS 설정 및 재시작 방법(화면 아래에서 '\n",
      " '위로 스와이핑)뿐만 아니라 iTunes 기기 관리 도구를 통해 iCloud 백업 파일 복원 등 다양한 문제 해결 단계를 안내합니다. 또한 '\n",
      " '사용자가 직접 수리 과정이나 배송 시간을 예약할지 아니면 애플 스토어 또는 공인 서비스 업체로부터 수리 진행 상황을 받을지 결정할 수도 '\n",
      " '있음을 알려줍니다[1] [3]')\n",
      "CPU times: user 2.54 ms, sys: 343 µs, total: 2.88 ms\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generated_text = ep.infer(payload, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d7781a-2184-4583-91b0-5d925ada857b",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "722e1c72-5450-4efd-858e-937bc499c73c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = 'iPhone을 기본 설정으로 재설정하면 충전 문제와 배터리 소모 문제를 해결할 수 있나요?'\n",
    "payload = ep.get_payload(instruction, input_text, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a61340d-fd87-4aea-831f-06bef3f500df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Response: 예'\n",
      "CPU times: user 2.06 ms, sys: 273 µs, total: 2.33 ms\n",
      "Wall time: 421 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generated_text = ep.infer(payload, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b668ab9a-8c0e-4668-b2ea-c53471a09569",
   "metadata": {},
   "source": [
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e4b9aed9-2f73-437c-a8dc-1e941fcd2a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = '고객이 iPhone 수리를 위해 가까운 Apple Store 또는 공인 서비스 제공업체에 예약하려면 어떤 조치를 취해야 하나요?'\n",
    "payload = ep.get_payload(instruction, input_text, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7dbbd31-ce58-4d57-9d30-29811de2dc20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Response: APPLE 스토어 및 공인 서비스 제공 업체 직원에게 문의하면 고객이 iPhone 수리를 위한 최적의 위치를 찾는데 '\n",
      " '도움이 될 수있다.')\n",
      "CPU times: user 2.24 ms, sys: 304 µs, total: 2.54 ms\n",
      "Wall time: 3.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generated_text = ep.infer(payload, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b85ca1-92f5-4d5a-b5d5-82f8655d49c0",
   "metadata": {},
   "source": [
    "### C. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "226408cb-94d1-4712-bb20-88b477106722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = '고객과 상담원 간의 대화에 대한 전반적인 감정 및 감정 점수는 얼마인가요?'\n",
    "payload = ep.get_payload(instruction, input_text, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2649b6e3-f77e-4f1c-bb67-9849cbc212bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Response: 전반적인 고객 만족도는 5점 만점 중 3.5점 정도였다(매우 만족 - 약간 불만족). 이 고객은 상담사와의 의사소통 '\n",
      " '과정 내내 친절하고 전문성있었으며, 자신에게 도움이나 지원을 주려고 노력한다는 점 때문인지 긍정적 평가 비율이 높아졌다고 한다.\"문제 '\n",
      " '해결 방법\", \"해결책 제안\", \"수리 절차 안내\" 등의 항목별 평점은 모두 4/4였으며, 이러한 조치에도 불구하고 문제가 계속 '\n",
      " '발생한다고 언급함으로써 개선 가능성이 낮다는 의견임을 시사한다[1] (참조 2 참조)')\n",
      "CPU times: user 2.42 ms, sys: 335 µs, total: 2.75 ms\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generated_text = ep.infer(payload, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8df69c5b-d254-4eea-9664-35afd70db706",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25841eb-4b6a-4f2b-8e85-d8effeaa732a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Clean Up\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "57321091-2855-4f3b-96ef-05bc783f50b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting model with name: kullm-polyglot-12-8b-v2-tgi-2023-07-23-14-05-06-080\n",
      "Deleting endpoint configuration with name: kullm-polyglot-12-8b-v2-tgi-2023-07-23-14-05-06-080\n",
      "Deleting endpoint with name: kullm-polyglot-12-8b-v2-tgi-2023-07-23-14-05-06-080\n"
     ]
    }
   ],
   "source": [
    "# Delete the SageMaker endpoint\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e22a1b-7f9d-42fb-b967-fb2a1689dc5a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# References\n",
    "---\n",
    "\n",
    "- Model 정보\n",
    "    - kullm-polyglot-5.8b-v2\n",
    "        - This model is a parameter-efficient fine-tuned version of EleutherAI/polyglot-ko-5.8b on a KULLM v2\n",
    "        - https://huggingface.co/nlpai-lab/kullm-polyglot-5.8b-v2        \n",
    "    - kullm-polyglot-12.8b-v2\n",
    "        - This model is a fine-tuned version of EleutherAI/polyglot-ko-12.8b on a KULLM v2\n",
    "        - https://huggingface.co/nlpai-lab/kullm-polyglot-12.8b-v2\n",
    "    - beomi/KoAlpaca-Polyglot-12.8B\n",
    "        - This model is a fine-tuned version of EleutherAI/polyglot-ko-12.8b on a KoAlpaca Dataset v1.1b\n",
    "        - https://huggingface.co/beomi/KoAlpaca-Polyglot-12.8B\n",
    "    - EleutherAI/polyglot-ko-12.8b\n",
    "        - Polyglot-Ko-12.8B was trained for 167 billion tokens over 301,000 steps on 256 A100 GPUs with the GPT-NeoX framework. It was trained as an autoregressive language model, using cross-entropy loss to maximize the likelihood of predicting the next token.\n",
    "        - License: Apache 2.0\n",
    "        - https://huggingface.co/EleutherAI/polyglot-ko-12.8b      \n",
    "- 코드\n",
    "    - [Boto3](https://github.com/aws/amazon-sagemaker-examples/blob/main/advanced_functionality/pytorch_deploy_large_GPT_model/GPT-J-6B-model-parallel-inference-DJL.ipynb)\n",
    "    - [Python SDK](https://github.com/aws/amazon-sagemaker-examples/blob/main/inference/generativeai/deepspeed/GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "    - [Kor LLM on SageMaker](https://github.com/gonsoomoon-ml/Kor-LLM-On-SageMaker)\n",
    "    - [AWS Generative AI Workshop for Korean language](https://github.com/aws-samples/aws-ai-ml-workshop-kr/tree/master/genai)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
